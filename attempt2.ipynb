{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"1s8m6WQbR88u9B9981e-iy4JlUCppG1mG","timestamp":1734695316804},{"file_id":"1Pm5XDZ_lwfQUbV30UpacmOcj0_Xb___K","timestamp":1581406558694},{"file_id":"1UZgYzHP_nQfh5o6EUu6XLY0CE-UpjWZW","timestamp":1581402660743},{"file_id":"1MX_zHpwEA0WZ1pYstGzdezJx45_IVgaB","timestamp":1581400837718},{"file_id":"1TYGkW7UI_yEiHnKM7EpqWOPreNlGzohA","timestamp":1581399399230},{"file_id":"1sdrerGJCxke700Rm8HsAn67Qno10sdQc","timestamp":1581398629897},{"file_id":"1Go7RjeKO_vfpwrL5iASjRqRckYdIarMu","timestamp":1581398111742},{"file_id":"12rQ81lvZSVuVJNLZPKEXcpEzpj1yG304","timestamp":1581397408180},{"file_id":"1t0jdeu4Rg-GRPm2RNs7q1-MvA_3uCPyW","timestamp":1581396738566},{"file_id":"1zx12oDfnadaVjEwQfUtAwfCQTSqZxRwj","timestamp":1581396281911},{"file_id":"1aFgWmHNJoCyZ56zRvoE8xUdAe285aWmb","timestamp":1581394625836}]},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{"id":"aO-7t1Y7-hV4"}},{"cell_type":"code","source":"from __future__ import print_function\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms","metadata":{"id":"8kH16rnZ7wt_","executionInfo":{"status":"ok","timestamp":1734695447615,"user_tz":-330,"elapsed":9034,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:40:21.596488Z","iopub.execute_input":"2024-12-21T09:40:21.596850Z","iopub.status.idle":"2024-12-21T09:40:21.601800Z","shell.execute_reply.started":"2024-12-21T09:40:21.596822Z","shell.execute_reply":"2024-12-21T09:40:21.600550Z"}},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":"## Data Transformations\n\nWe first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise.\n","metadata":{"id":"ky3f_Odl-7um"}},{"cell_type":"code","source":"# Train Phase transformations\ntrain_transforms = transforms.Compose([\n                                      #  transforms.Resize((28, 28)),\n                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n                                       transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values.\n                                       # Note the difference between (0.1307) and (0.1307,)\n                                       ])\n\n# Test Phase transformations\ntest_transforms = transforms.Compose([\n                                      #  transforms.Resize((28, 28)),\n                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.1307,), (0.3081,))\n                                       ])\n","metadata":{"id":"YtssFUKb-jqx","executionInfo":{"status":"ok","timestamp":1734695447616,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:40:21.603289Z","iopub.execute_input":"2024-12-21T09:40:21.603515Z","iopub.status.idle":"2024-12-21T09:40:21.619922Z","shell.execute_reply.started":"2024-12-21T09:40:21.603495Z","shell.execute_reply":"2024-12-21T09:40:21.619061Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"# Dataset and Creating Train/Test Split","metadata":{"id":"oQciFYo2B1mO"}},{"cell_type":"code","source":"train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\ntest = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)","metadata":{"id":"_4A84rlfDA23","executionInfo":{"status":"ok","timestamp":1734695452284,"user_tz":-330,"elapsed":4686,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e936be24-b2c7-40f4-ecb1-a06c12c6a5e1","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:40:21.621429Z","iopub.execute_input":"2024-12-21T09:40:21.621629Z","iopub.status.idle":"2024-12-21T09:40:21.740022Z","shell.execute_reply.started":"2024-12-21T09:40:21.621611Z","shell.execute_reply":"2024-12-21T09:40:21.739063Z"}},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":"# Dataloader Arguments & Test/Train Dataloaders\n","metadata":{"id":"qgldp_3-Dn0c"}},{"cell_type":"code","source":"SEED = 1\n\n# CUDA?\ncuda = torch.cuda.is_available()\nprint(\"CUDA Available?\", cuda)\n\n# For reproducibility\ntorch.manual_seed(SEED)\n\nif cuda:\n    torch.cuda.manual_seed(SEED)\n\n# dataloader arguments - something you'll fetch these from cmdprmt\ndataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n\n# train dataloader\ntrain_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n\n# test dataloader\ntest_loader = torch.utils.data.DataLoader(test, **dataloader_args)","metadata":{"id":"C8OLDR79DrHG","outputId":"87868eec-6bb4-4af8-8629-832ffbbeff5b","executionInfo":{"status":"ok","timestamp":1734695452722,"user_tz":-330,"elapsed":448,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:40:21.741381Z","iopub.execute_input":"2024-12-21T09:40:21.741600Z","iopub.status.idle":"2024-12-21T09:40:21.753958Z","shell.execute_reply.started":"2024-12-21T09:40:21.741582Z","shell.execute_reply":"2024-12-21T09:40:21.753108Z"}},"outputs":[{"name":"stdout","text":"CUDA Available? True\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"# The model\nLet's start with the model we first saw","metadata":{"id":"ubQL3H6RJL3h"}},{"cell_type":"code","source":"import torch.nn.functional as F\ndropout_value = 0.1\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # Input Block\n        self.convblock1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n            nn.Dropout(dropout_value)\n        ) # output_size = 26\n\n        # CONVOLUTION BLOCK 1\n        self.convblock2 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n            nn.Dropout(dropout_value)\n        ) # output_size = 24\n\n        # TRANSITION BLOCK 1\n        self.convblock3 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n        ) # output_size = 24\n        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n\n        # CONVOLUTION BLOCK 2\n        self.convblock4 = nn.Sequential(\n            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(20),\n            nn.Dropout(dropout_value)\n        ) # output_size = 10\n        self.convblock5 = nn.Sequential(\n            nn.Conv2d(in_channels=20, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(10),\n            nn.Dropout(dropout_value)\n        ) # output_size = 8\n        self.convblock6 = nn.Sequential(\n            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(10),\n            nn.Dropout(dropout_value)\n        ) # output_size = 6\n        self.convblock7 = nn.Sequential(\n            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=1, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(10),\n            nn.Dropout(dropout_value)\n        ) # output_size = 6\n        \n        # OUTPUT BLOCK\n        self.gap = nn.Sequential(\n            nn.AvgPool2d(kernel_size=6)\n        ) # output_size = 1\n\n        self.convblock8 = nn.Sequential(\n            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n            # nn.BatchNorm2d(10),\n            # nn.ReLU(),\n            # nn.Dropout(dropout_value)\n        ) \n\n\n        self.dropout = nn.Dropout(dropout_value)\n\n    def forward(self, x):\n        x = self.convblock1(x)\n        x = self.convblock2(x)\n        x = self.convblock3(x)\n        x = self.pool1(x)\n        x = self.convblock4(x)\n        x = self.convblock5(x)\n        x = self.convblock6(x)\n        x = self.convblock7(x)\n        x = self.gap(x)        \n        x = self.convblock8(x)\n\n        x = x.view(-1, 10)\n        return F.log_softmax(x, dim=-1)","metadata":{"id":"7FXQlB9kH1ov","executionInfo":{"status":"ok","timestamp":1734695452722,"user_tz":-330,"elapsed":14,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:40:21.754749Z","iopub.execute_input":"2024-12-21T09:40:21.755026Z","iopub.status.idle":"2024-12-21T09:40:21.766168Z","shell.execute_reply.started":"2024-12-21T09:40:21.755005Z","shell.execute_reply":"2024-12-21T09:40:21.765199Z"}},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":"# Model Params\nCan't emphasize on how important viewing Model Summary is.\nUnfortunately, there is no in-built model visualizer, so we have to take external help","metadata":{"id":"M3-vp8X9LCWo"}},{"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nprint(device)\nmodel = Net().to(device)\nsummary(model, input_size=(1, 28, 28))","metadata":{"id":"5skB97zIJQQe","outputId":"276ff497-b5a8-4ab4-e37d-75f4324be12a","executionInfo":{"status":"ok","timestamp":1734695457089,"user_tz":-330,"elapsed":4379,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:40:21.767026Z","iopub.execute_input":"2024-12-21T09:40:21.767286Z","iopub.status.idle":"2024-12-21T09:40:24.994641Z","shell.execute_reply.started":"2024-12-21T09:40:21.767254Z","shell.execute_reply":"2024-12-21T09:40:24.993543Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\ncuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 16, 26, 26]             144\n              ReLU-2           [-1, 16, 26, 26]               0\n       BatchNorm2d-3           [-1, 16, 26, 26]              32\n           Dropout-4           [-1, 16, 26, 26]               0\n            Conv2d-5           [-1, 16, 24, 24]           2,304\n              ReLU-6           [-1, 16, 24, 24]               0\n       BatchNorm2d-7           [-1, 16, 24, 24]              32\n           Dropout-8           [-1, 16, 24, 24]               0\n            Conv2d-9           [-1, 10, 24, 24]             160\n        MaxPool2d-10           [-1, 10, 12, 12]               0\n           Conv2d-11           [-1, 20, 10, 10]           1,800\n             ReLU-12           [-1, 20, 10, 10]               0\n      BatchNorm2d-13           [-1, 20, 10, 10]              40\n          Dropout-14           [-1, 20, 10, 10]               0\n           Conv2d-15             [-1, 10, 8, 8]           1,800\n             ReLU-16             [-1, 10, 8, 8]               0\n      BatchNorm2d-17             [-1, 10, 8, 8]              20\n          Dropout-18             [-1, 10, 8, 8]               0\n           Conv2d-19             [-1, 10, 6, 6]             900\n             ReLU-20             [-1, 10, 6, 6]               0\n      BatchNorm2d-21             [-1, 10, 6, 6]              20\n          Dropout-22             [-1, 10, 6, 6]               0\n           Conv2d-23             [-1, 10, 6, 6]             900\n             ReLU-24             [-1, 10, 6, 6]               0\n      BatchNorm2d-25             [-1, 10, 6, 6]              20\n          Dropout-26             [-1, 10, 6, 6]               0\n        AvgPool2d-27             [-1, 10, 1, 1]               0\n           Conv2d-28             [-1, 10, 1, 1]             100\n================================================================\nTotal params: 8,272\nTrainable params: 8,272\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.77\nParams size (MB): 0.03\nEstimated Total Size (MB): 0.80\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"# Training and Testing\n\nLooking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs.\n\nLet's write train and test functions","metadata":{"id":"1__x_SbrL7z3"}},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_losses = []\ntest_losses = []\ntrain_acc = []\ntest_acc = []\n\ndef train(model, device, train_loader, optimizer, epoch):\n  model.train()\n  pbar = tqdm(train_loader)\n  correct = 0\n  processed = 0\n  for batch_idx, (data, target) in enumerate(pbar):\n    # get samples\n    data, target = data.to(device), target.to(device)\n\n    # Init\n    optimizer.zero_grad()\n    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n\n    # Predict\n    y_pred = model(data)\n\n    # Calculate loss\n    loss = F.nll_loss(y_pred, target)\n    train_losses.append(loss)\n\n    # Backpropagation\n    loss.backward()\n    optimizer.step()\n\n    # Update pbar-tqdm\n\n    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n    correct += pred.eq(target.view_as(pred)).sum().item()\n    processed += len(data)\n\n    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n    train_acc.append(100*correct/processed)\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    test_losses.append(test_loss)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n    test_acc.append(100. * correct / len(test_loader.dataset))","metadata":{"id":"fbkF2nN_LYIb","executionInfo":{"status":"ok","timestamp":1734695457090,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:40:24.995806Z","iopub.execute_input":"2024-12-21T09:40:24.996063Z","iopub.status.idle":"2024-12-21T09:40:25.805901Z","shell.execute_reply.started":"2024-12-21T09:40:24.996043Z","shell.execute_reply":"2024-12-21T09:40:25.805206Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\n\nmodel =  Net().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\nscheduler = StepLR(optimizer, step_size=6, gamma=0.5)\n\n\nEPOCHS = 15\nfor epoch in range(EPOCHS):\n    print(\"EPOCH:\", epoch)\n    train(model, device, train_loader, optimizer, epoch)\n    scheduler.step()\n    test(model, device, test_loader)","metadata":{"id":"aE5Le6FYHhc8","outputId":"ebf38ded-1b5f-4612-a3e2-ff212ab76c65","executionInfo":{"status":"ok","timestamp":1734699273509,"user_tz":-330,"elapsed":462316,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:40:25.807991Z","iopub.execute_input":"2024-12-21T09:40:25.808337Z","iopub.status.idle":"2024-12-21T09:43:09.215660Z","shell.execute_reply.started":"2024-12-21T09:40:25.808305Z","shell.execute_reply":"2024-12-21T09:43:09.214463Z"}},"outputs":[{"name":"stdout","text":"EPOCH: 0\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.15089042484760284 Batch_id=468 Accuracy=91.60: 100%|██████████| 469/469 [00:09<00:00, 51.00it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0538, Accuracy: 9822/10000 (98.22%)\n\nEPOCH: 1\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.036233872175216675 Batch_id=468 Accuracy=97.32: 100%|██████████| 469/469 [00:09<00:00, 50.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0396, Accuracy: 9879/10000 (98.79%)\n\nEPOCH: 2\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.04825673624873161 Batch_id=468 Accuracy=97.86: 100%|██████████| 469/469 [00:09<00:00, 48.73it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0366, Accuracy: 9889/10000 (98.89%)\n\nEPOCH: 3\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.1268152892589569 Batch_id=468 Accuracy=98.04: 100%|██████████| 469/469 [00:09<00:00, 51.26it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0299, Accuracy: 9908/10000 (99.08%)\n\nEPOCH: 4\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.09500027447938919 Batch_id=468 Accuracy=98.30: 100%|██████████| 469/469 [00:09<00:00, 50.87it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0304, Accuracy: 9912/10000 (99.12%)\n\nEPOCH: 5\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.02679309993982315 Batch_id=468 Accuracy=98.42: 100%|██████████| 469/469 [00:09<00:00, 47.50it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0294, Accuracy: 9914/10000 (99.14%)\n\nEPOCH: 6\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.02753552794456482 Batch_id=468 Accuracy=98.59: 100%|██████████| 469/469 [00:09<00:00, 50.52it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0252, Accuracy: 9928/10000 (99.28%)\n\nEPOCH: 7\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.08995357900857925 Batch_id=468 Accuracy=98.67: 100%|██████████| 469/469 [00:09<00:00, 50.40it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0241, Accuracy: 9933/10000 (99.33%)\n\nEPOCH: 8\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.008798494003713131 Batch_id=468 Accuracy=98.77: 100%|██████████| 469/469 [00:09<00:00, 47.98it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0241, Accuracy: 9931/10000 (99.31%)\n\nEPOCH: 9\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.0394267663359642 Batch_id=468 Accuracy=98.82: 100%|██████████| 469/469 [00:09<00:00, 49.02it/s]   \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0234, Accuracy: 9931/10000 (99.31%)\n\nEPOCH: 10\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.025602566078305244 Batch_id=468 Accuracy=98.82: 100%|██████████| 469/469 [00:09<00:00, 48.37it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0226, Accuracy: 9936/10000 (99.36%)\n\nEPOCH: 11\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.06453240662813187 Batch_id=468 Accuracy=98.87: 100%|██████████| 469/469 [00:10<00:00, 46.21it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0212, Accuracy: 9936/10000 (99.36%)\n\nEPOCH: 12\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.010025572963058949 Batch_id=468 Accuracy=98.91: 100%|██████████| 469/469 [00:09<00:00, 48.85it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0208, Accuracy: 9934/10000 (99.34%)\n\nEPOCH: 13\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.01359491515904665 Batch_id=468 Accuracy=99.00: 100%|██████████| 469/469 [00:09<00:00, 48.39it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0199, Accuracy: 9937/10000 (99.37%)\n\nEPOCH: 14\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.01261117309331894 Batch_id=468 Accuracy=98.95: 100%|██████████| 469/469 [00:09<00:00, 48.52it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0197, Accuracy: 9932/10000 (99.32%)\n\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"","metadata":{"id":"wjO3RK9UEnvF","executionInfo":{"status":"aborted","timestamp":1734695957296,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"trusted":true},"outputs":[],"execution_count":null}]}