{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"1s8m6WQbR88u9B9981e-iy4JlUCppG1mG","timestamp":1734695316804},{"file_id":"1Pm5XDZ_lwfQUbV30UpacmOcj0_Xb___K","timestamp":1581406558694},{"file_id":"1UZgYzHP_nQfh5o6EUu6XLY0CE-UpjWZW","timestamp":1581402660743},{"file_id":"1MX_zHpwEA0WZ1pYstGzdezJx45_IVgaB","timestamp":1581400837718},{"file_id":"1TYGkW7UI_yEiHnKM7EpqWOPreNlGzohA","timestamp":1581399399230},{"file_id":"1sdrerGJCxke700Rm8HsAn67Qno10sdQc","timestamp":1581398629897},{"file_id":"1Go7RjeKO_vfpwrL5iASjRqRckYdIarMu","timestamp":1581398111742},{"file_id":"12rQ81lvZSVuVJNLZPKEXcpEzpj1yG304","timestamp":1581397408180},{"file_id":"1t0jdeu4Rg-GRPm2RNs7q1-MvA_3uCPyW","timestamp":1581396738566},{"file_id":"1zx12oDfnadaVjEwQfUtAwfCQTSqZxRwj","timestamp":1581396281911},{"file_id":"1aFgWmHNJoCyZ56zRvoE8xUdAe285aWmb","timestamp":1581394625836}]},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{"id":"aO-7t1Y7-hV4"}},{"cell_type":"code","source":"from __future__ import print_function\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms","metadata":{"id":"8kH16rnZ7wt_","executionInfo":{"status":"ok","timestamp":1734695447615,"user_tz":-330,"elapsed":9034,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:47:23.712806Z","iopub.execute_input":"2024-12-21T09:47:23.713268Z","iopub.status.idle":"2024-12-21T09:47:23.718061Z","shell.execute_reply.started":"2024-12-21T09:47:23.713231Z","shell.execute_reply":"2024-12-21T09:47:23.717168Z"}},"outputs":[],"execution_count":73},{"cell_type":"markdown","source":"## Data Transformations\n\nWe first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise.\n","metadata":{"id":"ky3f_Odl-7um"}},{"cell_type":"code","source":"# Train Phase transformations\ntrain_transforms = transforms.Compose([\n                                      #  transforms.Resize((28, 28)),\n                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n                                       transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values.\n                                       # Note the difference between (0.1307) and (0.1307,)\n                                       ])\n\n# Test Phase transformations\ntest_transforms = transforms.Compose([\n                                      #  transforms.Resize((28, 28)),\n                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.1307,), (0.3081,))\n                                       ])\n","metadata":{"id":"YtssFUKb-jqx","executionInfo":{"status":"ok","timestamp":1734695447616,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:47:23.719257Z","iopub.execute_input":"2024-12-21T09:47:23.719517Z","iopub.status.idle":"2024-12-21T09:47:23.735909Z","shell.execute_reply.started":"2024-12-21T09:47:23.719498Z","shell.execute_reply":"2024-12-21T09:47:23.735300Z"}},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"# Dataset and Creating Train/Test Split","metadata":{"id":"oQciFYo2B1mO"}},{"cell_type":"code","source":"train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\ntest = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)","metadata":{"id":"_4A84rlfDA23","executionInfo":{"status":"ok","timestamp":1734695452284,"user_tz":-330,"elapsed":4686,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e936be24-b2c7-40f4-ecb1-a06c12c6a5e1","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:47:23.737670Z","iopub.execute_input":"2024-12-21T09:47:23.737891Z","iopub.status.idle":"2024-12-21T09:47:23.844664Z","shell.execute_reply.started":"2024-12-21T09:47:23.737872Z","shell.execute_reply":"2024-12-21T09:47:23.843781Z"}},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":"# Dataloader Arguments & Test/Train Dataloaders\n","metadata":{"id":"qgldp_3-Dn0c"}},{"cell_type":"code","source":"SEED = 1\n\n# CUDA?\ncuda = torch.cuda.is_available()\nprint(\"CUDA Available?\", cuda)\n\n# For reproducibility\ntorch.manual_seed(SEED)\n\nif cuda:\n    torch.cuda.manual_seed(SEED)\n\n# dataloader arguments - something you'll fetch these from cmdprmt\ndataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n\n# train dataloader\ntrain_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n\n# test dataloader\ntest_loader = torch.utils.data.DataLoader(test, **dataloader_args)","metadata":{"id":"C8OLDR79DrHG","outputId":"87868eec-6bb4-4af8-8629-832ffbbeff5b","executionInfo":{"status":"ok","timestamp":1734695452722,"user_tz":-330,"elapsed":448,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:47:23.845776Z","iopub.execute_input":"2024-12-21T09:47:23.846103Z","iopub.status.idle":"2024-12-21T09:47:23.859957Z","shell.execute_reply.started":"2024-12-21T09:47:23.846067Z","shell.execute_reply":"2024-12-21T09:47:23.859041Z"}},"outputs":[{"name":"stdout","text":"CUDA Available? True\n","output_type":"stream"}],"execution_count":76},{"cell_type":"markdown","source":"# The model\nLet's start with the model we first saw","metadata":{"id":"ubQL3H6RJL3h"}},{"cell_type":"code","source":"import torch.nn.functional as F\ndropout_value = 0.1\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # Input Block\n        self.convblock1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n            nn.Dropout(dropout_value)\n        ) # output_size = 26\n\n        # CONVOLUTION BLOCK 1\n        self.convblock2 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n            nn.Dropout(dropout_value)\n        ) # output_size = 24\n\n        # TRANSITION BLOCK 1\n        self.convblock3 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n        ) # output_size = 24\n        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n\n        # CONVOLUTION BLOCK 2\n        self.convblock4 = nn.Sequential(\n            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(20),\n            nn.Dropout(dropout_value)\n        ) # output_size = 10\n        self.convblock5 = nn.Sequential(\n            nn.Conv2d(in_channels=20, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(10),\n            nn.Dropout(dropout_value)\n        ) # output_size = 8\n        self.convblock6 = nn.Sequential(\n            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(10),\n            nn.Dropout(dropout_value)\n        ) # output_size = 6\n        self.convblock7 = nn.Sequential(\n            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=1, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(10),\n            nn.Dropout(dropout_value)\n        ) # output_size = 6\n        \n        # OUTPUT BLOCK\n        self.gap = nn.Sequential(\n            nn.AvgPool2d(kernel_size=6)\n        ) # output_size = 1\n\n        self.convblock8 = nn.Sequential(\n            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n            # nn.BatchNorm2d(10),\n            # nn.ReLU(),\n            # nn.Dropout(dropout_value)\n        ) \n\n\n        self.dropout = nn.Dropout(dropout_value)\n\n    def forward(self, x):\n        x = self.convblock1(x)\n        x = self.convblock2(x)\n        x = self.convblock3(x)\n        x = self.pool1(x)\n        x = self.convblock4(x)\n        x = self.convblock5(x)\n        x = self.convblock6(x)\n        x = self.convblock7(x)\n        x = self.gap(x)        \n        x = self.convblock8(x)\n\n        x = x.view(-1, 10)\n        return F.log_softmax(x, dim=-1)","metadata":{"id":"7FXQlB9kH1ov","executionInfo":{"status":"ok","timestamp":1734695452722,"user_tz":-330,"elapsed":14,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:47:23.860978Z","iopub.execute_input":"2024-12-21T09:47:23.861302Z","iopub.status.idle":"2024-12-21T09:47:23.872507Z","shell.execute_reply.started":"2024-12-21T09:47:23.861268Z","shell.execute_reply":"2024-12-21T09:47:23.871371Z"}},"outputs":[],"execution_count":77},{"cell_type":"markdown","source":"# Model Params\nCan't emphasize on how important viewing Model Summary is.\nUnfortunately, there is no in-built model visualizer, so we have to take external help","metadata":{"id":"M3-vp8X9LCWo"}},{"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nprint(device)\nmodel = Net().to(device)\nsummary(model, input_size=(1, 28, 28))","metadata":{"id":"5skB97zIJQQe","outputId":"276ff497-b5a8-4ab4-e37d-75f4324be12a","executionInfo":{"status":"ok","timestamp":1734695457089,"user_tz":-330,"elapsed":4379,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:47:23.873275Z","iopub.execute_input":"2024-12-21T09:47:23.873811Z","iopub.status.idle":"2024-12-21T09:47:27.106833Z","shell.execute_reply.started":"2024-12-21T09:47:23.873781Z","shell.execute_reply":"2024-12-21T09:47:27.105800Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\ncuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 16, 26, 26]             144\n              ReLU-2           [-1, 16, 26, 26]               0\n       BatchNorm2d-3           [-1, 16, 26, 26]              32\n           Dropout-4           [-1, 16, 26, 26]               0\n            Conv2d-5           [-1, 16, 24, 24]           2,304\n              ReLU-6           [-1, 16, 24, 24]               0\n       BatchNorm2d-7           [-1, 16, 24, 24]              32\n           Dropout-8           [-1, 16, 24, 24]               0\n            Conv2d-9           [-1, 10, 24, 24]             160\n        MaxPool2d-10           [-1, 10, 12, 12]               0\n           Conv2d-11           [-1, 20, 10, 10]           1,800\n             ReLU-12           [-1, 20, 10, 10]               0\n      BatchNorm2d-13           [-1, 20, 10, 10]              40\n          Dropout-14           [-1, 20, 10, 10]               0\n           Conv2d-15             [-1, 10, 8, 8]           1,800\n             ReLU-16             [-1, 10, 8, 8]               0\n      BatchNorm2d-17             [-1, 10, 8, 8]              20\n          Dropout-18             [-1, 10, 8, 8]               0\n           Conv2d-19             [-1, 10, 6, 6]             900\n             ReLU-20             [-1, 10, 6, 6]               0\n      BatchNorm2d-21             [-1, 10, 6, 6]              20\n          Dropout-22             [-1, 10, 6, 6]               0\n           Conv2d-23             [-1, 10, 6, 6]             900\n             ReLU-24             [-1, 10, 6, 6]               0\n      BatchNorm2d-25             [-1, 10, 6, 6]              20\n          Dropout-26             [-1, 10, 6, 6]               0\n        AvgPool2d-27             [-1, 10, 1, 1]               0\n           Conv2d-28             [-1, 10, 1, 1]             100\n================================================================\nTotal params: 8,272\nTrainable params: 8,272\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.77\nParams size (MB): 0.03\nEstimated Total Size (MB): 0.80\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"# Training and Testing\n\nLooking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs.\n\nLet's write train and test functions","metadata":{"id":"1__x_SbrL7z3"}},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_losses = []\ntest_losses = []\ntrain_acc = []\ntest_acc = []\n\ndef train(model, device, train_loader, optimizer, epoch):\n  model.train()\n  pbar = tqdm(train_loader)\n  correct = 0\n  processed = 0\n  for batch_idx, (data, target) in enumerate(pbar):\n    # get samples\n    data, target = data.to(device), target.to(device)\n\n    # Init\n    optimizer.zero_grad()\n    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n\n    # Predict\n    y_pred = model(data)\n\n    # Calculate loss\n    loss = F.nll_loss(y_pred, target)\n    train_losses.append(loss)\n\n    # Backpropagation\n    loss.backward()\n    optimizer.step()\n\n    # Update pbar-tqdm\n\n    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n    correct += pred.eq(target.view_as(pred)).sum().item()\n    processed += len(data)\n\n    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n    train_acc.append(100*correct/processed)\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    test_losses.append(test_loss)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n    test_acc.append(100. * correct / len(test_loader.dataset))","metadata":{"id":"fbkF2nN_LYIb","executionInfo":{"status":"ok","timestamp":1734695457090,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:47:27.108092Z","iopub.execute_input":"2024-12-21T09:47:27.108467Z","iopub.status.idle":"2024-12-21T09:47:27.376908Z","shell.execute_reply.started":"2024-12-21T09:47:27.108417Z","shell.execute_reply":"2024-12-21T09:47:27.376260Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\n\nmodel =  Net().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\nscheduler = StepLR(optimizer, step_size=3, gamma=0.9)\n\n\nEPOCHS = 15\nfor epoch in range(EPOCHS):\n    print(\"EPOCH:\", epoch)\n    train(model, device, train_loader, optimizer, epoch)\n    scheduler.step()\n    test(model, device, test_loader)","metadata":{"id":"aE5Le6FYHhc8","outputId":"ebf38ded-1b5f-4612-a3e2-ff212ab76c65","executionInfo":{"status":"ok","timestamp":1734699273509,"user_tz":-330,"elapsed":462316,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T09:47:27.378856Z","iopub.execute_input":"2024-12-21T09:47:27.379187Z","iopub.status.idle":"2024-12-21T09:50:08.736275Z","shell.execute_reply.started":"2024-12-21T09:47:27.379155Z","shell.execute_reply":"2024-12-21T09:50:08.735093Z"}},"outputs":[{"name":"stdout","text":"EPOCH: 0\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.17932111024856567 Batch_id=468 Accuracy=91.43: 100%|██████████| 469/469 [00:09<00:00, 51.04it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0598, Accuracy: 9821/10000 (98.21%)\n\nEPOCH: 1\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.059695612639188766 Batch_id=468 Accuracy=97.31: 100%|██████████| 469/469 [00:09<00:00, 48.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0384, Accuracy: 9889/10000 (98.89%)\n\nEPOCH: 2\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.03814145550131798 Batch_id=468 Accuracy=97.81: 100%|██████████| 469/469 [00:09<00:00, 51.36it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0300, Accuracy: 9907/10000 (99.07%)\n\nEPOCH: 3\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.0676000565290451 Batch_id=468 Accuracy=98.11: 100%|██████████| 469/469 [00:09<00:00, 51.24it/s]   \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0308, Accuracy: 9907/10000 (99.07%)\n\nEPOCH: 4\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.03524812310934067 Batch_id=468 Accuracy=98.24: 100%|██████████| 469/469 [00:09<00:00, 49.40it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0296, Accuracy: 9898/10000 (98.98%)\n\nEPOCH: 5\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.03188560530543327 Batch_id=468 Accuracy=98.43: 100%|██████████| 469/469 [00:09<00:00, 50.53it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0282, Accuracy: 9908/10000 (99.08%)\n\nEPOCH: 6\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.026305951178073883 Batch_id=468 Accuracy=98.56: 100%|██████████| 469/469 [00:09<00:00, 49.33it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0234, Accuracy: 9930/10000 (99.30%)\n\nEPOCH: 7\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.02448824606835842 Batch_id=468 Accuracy=98.51: 100%|██████████| 469/469 [00:09<00:00, 47.40it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0257, Accuracy: 9923/10000 (99.23%)\n\nEPOCH: 8\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.05482727289199829 Batch_id=468 Accuracy=98.60: 100%|██████████| 469/469 [00:09<00:00, 49.07it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0229, Accuracy: 9926/10000 (99.26%)\n\nEPOCH: 9\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.1321008950471878 Batch_id=468 Accuracy=98.64: 100%|██████████| 469/469 [00:09<00:00, 50.60it/s]   \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0224, Accuracy: 9920/10000 (99.20%)\n\nEPOCH: 10\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.033024851232767105 Batch_id=468 Accuracy=98.73: 100%|██████████| 469/469 [00:09<00:00, 47.81it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0217, Accuracy: 9925/10000 (99.25%)\n\nEPOCH: 11\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.0732300654053688 Batch_id=468 Accuracy=98.76: 100%|██████████| 469/469 [00:09<00:00, 50.25it/s]   \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0215, Accuracy: 9932/10000 (99.32%)\n\nEPOCH: 12\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.03338253125548363 Batch_id=468 Accuracy=98.79: 100%|██████████| 469/469 [00:09<00:00, 50.72it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0235, Accuracy: 9928/10000 (99.28%)\n\nEPOCH: 13\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.016463203355669975 Batch_id=468 Accuracy=98.83: 100%|██████████| 469/469 [00:09<00:00, 48.17it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0210, Accuracy: 9923/10000 (99.23%)\n\nEPOCH: 14\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.02052616886794567 Batch_id=468 Accuracy=98.85: 100%|██████████| 469/469 [00:09<00:00, 49.95it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0170, Accuracy: 9938/10000 (99.38%)\n\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"","metadata":{"id":"wjO3RK9UEnvF","executionInfo":{"status":"aborted","timestamp":1734695957296,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sundarrajan Babu","userId":"08416208056099048758"}},"trusted":true},"outputs":[],"execution_count":null}]}